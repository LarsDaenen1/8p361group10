{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96138156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "#import models\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd95fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "    # dataset parameters\n",
    "    train_path = os.path.join(base_dir, 'train+val', 'train')\n",
    "    valid_path = os.path.join(base_dir, 'train+val', 'valid')\n",
    "\n",
    "    # instantiate data generators\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pretrained(pretrained_network):\n",
    "    \n",
    "    IMAGE_SIZE = 96\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    output = pretrained_network(input)\n",
    "    output = GlobalAveragePooling2D()(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    # note the lower lr compared to the cnn example\n",
    "    model.compile(SGD(learning_rate=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # print a summary of the model on screen\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1906f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_ResNet = ResNet152V2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "pretrained_EfficientNet = EfficientNetB5(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "pretrained_VGG = VGG16(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "pretrained_Xception = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "names = ['ResNet', \"EfficientNet\", \"VGG16\", \"Xception\"]\n",
    "pretrained_models = [pretrained_ResNet, pretrained_EfficientNet, pretrained_VGG, pretrained_Xception]\n",
    "models = [prepare_pretrained(pretrained_ResNet)] #[prepare_pretrained(i) for i in pretrained_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363519f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data generators\n",
    "train_gen, val_gen = get_pcam_generators(r\"C:\\Users\\20192653\\Documents\\8P361 - Project imaging\\8p361-project-imaging-master\\8p361-project-imaging-master\\data\")\n",
    "\n",
    "for i,model in enumerate(models):\n",
    "    # save the model and weights\n",
    "    model_name = names[i]\n",
    "    model_filepath = model_name + '.json'\n",
    "    weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "    model_json = model.to_json() # serialize model to JSON\n",
    "    with open(model_filepath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "\n",
    "    # define the model checkpoint and Tensorboard callbacks\n",
    "    checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "    callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "    # train the model, note that we define \"mini-epochs\"\n",
    "    train_steps = train_gen.n//train_gen.batch_size//20\n",
    "    val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "    # since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "        # not used during training\n",
    "\n",
    "    history = model.fit(train_gen, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=20,\n",
    "                        callbacks=callbacks_list)\n",
    "    model = tf.keras.models.load_model(weights_filepath)\n",
    "    y_pred = model.predict(val_gen, verbose=1).ravel()\n",
    "    y_true = val_gen.labels\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    from sklearn.metrics import auc\n",
    "    auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve of {}'.format(models[i]))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0feee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
