{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bdbe78",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c9a735a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import scipy\n",
    "\n",
    "df_inception_old = pd.read_csv (r'C:\\Users\\20192236\\Downloads\\results\\results\\Inception_submission.csv')\n",
    "df_efficient_old = pd.read_csv (r'C:\\Users\\20192236\\Downloads\\results\\results\\EfficientNet_submission.csv')\n",
    "df_resnet_old = pd.read_csv (r'C:\\Users\\20192236\\Downloads\\results\\results\\ResNet_submission.csv')\n",
    "df_vgg16_old = pd.read_csv (r'C:\\Users\\20192236\\Downloads\\results\\results\\VGG16_submission.csv')\n",
    "df_xception_old = pd.read_csv (r'C:\\Users\\20192236\\Downloads\\results\\results\\Xception_submission.csv')\n",
    "\n",
    "df_inception = df_inception_old.rename(columns={'label':'label_inception'}, errors='raise')\n",
    "df_efficient = df_efficient_old.rename(columns={'label':'label_efficient'}, errors='raise')\n",
    "df_resnet = df_resnet_old.rename(columns={'label':'label_resnet'}, errors='raise')\n",
    "df_vgg16 = df_vgg16_old.rename(columns={'label':'label_vgg16'}, errors='raise')\n",
    "df_xception = df_xception_old.rename(columns={'label':'label_xception'}, errors='raise')\n",
    "\n",
    "all_probs = pd.DataFrame(data=[df_inception['id'], df_inception['label_inception'], df_xception['label_xception'], df_efficient['label_efficient'], df_resnet['label_resnet'], df_vgg16['label_vgg16']])\n",
    "all_probs = all_probs.transpose()\n",
    "all_probs['mu'] = 0\n",
    "all_probs['sigma'] = 0\n",
    "all_probs['mu'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f20a0d",
   "metadata": {},
   "source": [
    "Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c6960a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_inception</th>\n",
       "      <th>label_xception</th>\n",
       "      <th>label_efficient</th>\n",
       "      <th>label_resnet</th>\n",
       "      <th>label_vgg16</th>\n",
       "      <th>mu</th>\n",
       "      <th>sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00006537328c33e284c973d7b39d340809f7271b</td>\n",
       "      <td>0.478034</td>\n",
       "      <td>0.993316</td>\n",
       "      <td>0.503348</td>\n",
       "      <td>0.999171</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000ec92553fda4ce39889f9226ace43cae3364e</td>\n",
       "      <td>0.518892</td>\n",
       "      <td>0.95245</td>\n",
       "      <td>0.959156</td>\n",
       "      <td>0.93481</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00024a6dee61f12f7856b0fc6be20bc7a48ba3d2</td>\n",
       "      <td>0.575155</td>\n",
       "      <td>0.835915</td>\n",
       "      <td>0.396475</td>\n",
       "      <td>0.992789</td>\n",
       "      <td>0.89388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000253dfaa0be9d0d100283b22284ab2f6b643f6</td>\n",
       "      <td>0.648605</td>\n",
       "      <td>0.675391</td>\n",
       "      <td>0.560131</td>\n",
       "      <td>0.984799</td>\n",
       "      <td>0.996066</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000270442cc15af719583a8172c87cd2bd9c7746</td>\n",
       "      <td>0.192873</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.01143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57453</th>\n",
       "      <td>fffdd1cbb1ac0800f65309f344dd15e9331e1c53</td>\n",
       "      <td>0.147148</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.022752</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57454</th>\n",
       "      <td>fffdf4b82ba01f9cae88b9fa45be103344d9f6e3</td>\n",
       "      <td>0.176237</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.048932</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57455</th>\n",
       "      <td>fffec7da56b54258038b0d382b3d55010eceb9d7</td>\n",
       "      <td>0.290546</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57456</th>\n",
       "      <td>ffff276d06a9e3fffc456f2a5a7a3fd1a2d322c6</td>\n",
       "      <td>0.420927</td>\n",
       "      <td>0.503107</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.757315</td>\n",
       "      <td>0.834874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57457</th>\n",
       "      <td>ffffeb4c0756098c7f589b7beec08ef1899093b5</td>\n",
       "      <td>0.134338</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.058762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57458 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id label_inception  \\\n",
       "0      00006537328c33e284c973d7b39d340809f7271b        0.478034   \n",
       "1      0000ec92553fda4ce39889f9226ace43cae3364e        0.518892   \n",
       "2      00024a6dee61f12f7856b0fc6be20bc7a48ba3d2        0.575155   \n",
       "3      000253dfaa0be9d0d100283b22284ab2f6b643f6        0.648605   \n",
       "4      000270442cc15af719583a8172c87cd2bd9c7746        0.192873   \n",
       "...                                         ...             ...   \n",
       "57453  fffdd1cbb1ac0800f65309f344dd15e9331e1c53        0.147148   \n",
       "57454  fffdf4b82ba01f9cae88b9fa45be103344d9f6e3        0.176237   \n",
       "57455  fffec7da56b54258038b0d382b3d55010eceb9d7        0.290546   \n",
       "57456  ffff276d06a9e3fffc456f2a5a7a3fd1a2d322c6        0.420927   \n",
       "57457  ffffeb4c0756098c7f589b7beec08ef1899093b5        0.134338   \n",
       "\n",
       "      label_xception label_efficient label_resnet label_vgg16  mu  sigma  \n",
       "0           0.993316        0.503348     0.999171    0.998745   0      0  \n",
       "1            0.95245        0.959156      0.93481      0.6989   0      0  \n",
       "2           0.835915        0.396475     0.992789     0.89388   0      0  \n",
       "3           0.675391        0.560131     0.984799    0.996066   0      0  \n",
       "4           0.002332        0.019242     0.001395     0.01143   0      0  \n",
       "...              ...             ...          ...         ...  ..    ...  \n",
       "57453       0.000633        0.022752     0.035865    0.001352   0      0  \n",
       "57454       0.013224        0.001911     0.048932    0.009463   0      0  \n",
       "57455       0.000219        0.014254       0.0145    0.001723   0      0  \n",
       "57456       0.503107          0.0917     0.757315    0.834874   0      0  \n",
       "57457       0.033223        0.007258     0.007222    0.058762   0      0  \n",
       "\n",
       "[57458 rows x 8 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = []\n",
    "sigma = []\n",
    "for i in range(len(all_probs)):\n",
    "    mu.append(np.mean(all_probs.iloc[i, 1:6].values))\n",
    "    sigma.append(np.std(all_probs.iloc[i, 1:6].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4527fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21c61678",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0 0 0 0 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19236/1564043688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mall_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_probs_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpred_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1324\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \"\"\"\n\u001b[1;32m--> 663\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m   1382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1385\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    770\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0 0 0 0 0].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "def predict_Bayes_class(X,mu_list,sigma_list): \n",
    "    #Returns the predicted class from an optimal bayes classifier - distributions must be known\n",
    "    scores_list = []\n",
    "    classes = len(mu_list)\n",
    "    \n",
    "    for p in range(classes):\n",
    "        score = scipy.stats.multivariate_normal.pdf(X, mean=mu_list[p], cov=sigma_list[p])\n",
    "        scores_list.append(score)\n",
    "             \n",
    "    return np.argmax(scores_list)\n",
    "predict_Bayes_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "588fdfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7945228660000001,\n",
       " 0.8128417540000001,\n",
       " 0.73884269,\n",
       " 0.77299857,\n",
       " 0.04545442966,\n",
       " 0.14903411640000003,\n",
       " 0.3452895165,\n",
       " 0.45030844800000003,\n",
       " 0.6884171208,\n",
       " 0.793192514,\n",
       " 0.26420837919999995,\n",
       " 0.08456170464,\n",
       " 0.785263782,\n",
       " 0.4453313714,\n",
       " 0.0358595413,\n",
       " 0.6557827119999999,\n",
       " 0.152138244,\n",
       " 0.1419026622,\n",
       " 0.183711935764,\n",
       " 0.201850272,\n",
       " 0.05811457498,\n",
       " 0.094735227,\n",
       " 0.20423416020000001,\n",
       " 0.594596046,\n",
       " 0.25456892700000006,\n",
       " 0.0748575578,\n",
       " 0.1776038458,\n",
       " 0.438472836,\n",
       " 0.221243017,\n",
       " 0.18158329899999998,\n",
       " 0.5988001512000001,\n",
       " 0.22454897219999997,\n",
       " 0.33698910140000005,\n",
       " 0.18492252699999998,\n",
       " 0.1088346738,\n",
       " 0.026036106059999998,\n",
       " 0.948558584,\n",
       " 0.03469459379999999,\n",
       " 0.5327158068,\n",
       " 0.723589336,\n",
       " 0.2495629794,\n",
       " 0.14235754720000002,\n",
       " 0.10300285940000001,\n",
       " 0.48946081599999997,\n",
       " 0.10633364638000001,\n",
       " 0.8626956680000001,\n",
       " 0.172020104,\n",
       " 0.0908223028,\n",
       " 0.07358540291999999,\n",
       " 0.16964915900000002,\n",
       " 0.837865858,\n",
       " 0.047111980600000006,\n",
       " 0.7162093700000001,\n",
       " 0.30336045720000004,\n",
       " 0.8110118780000001,\n",
       " 0.578280072,\n",
       " 0.600905362,\n",
       " 0.3390340012,\n",
       " 0.204440292,\n",
       " 0.0423219098,\n",
       " 0.865685534,\n",
       " 0.9003697900000001,\n",
       " 0.19982206279999998,\n",
       " 0.048268166200000004,\n",
       " 0.06373360410000001,\n",
       " 0.07552663676000002,\n",
       " 0.757047068,\n",
       " 0.568943072,\n",
       " 0.814020356,\n",
       " 0.793047292,\n",
       " 0.16444477259999998,\n",
       " 0.048688453459999996,\n",
       " 0.7907873879999998,\n",
       " 0.31216186160000003,\n",
       " 0.0795336648,\n",
       " 0.39004397799999996,\n",
       " 0.89641573,\n",
       " 0.962426102,\n",
       " 0.8741094799999999,\n",
       " 0.5677874980000001,\n",
       " 0.6845952824,\n",
       " 0.6230169780000001,\n",
       " 0.25268634160000003,\n",
       " 0.10393444221999999,\n",
       " 0.768991736,\n",
       " 0.2500566644,\n",
       " 0.703409906,\n",
       " 0.553392134,\n",
       " 0.537209112,\n",
       " 0.35926982479999997,\n",
       " 0.406087844,\n",
       " 0.3007432986,\n",
       " 0.055538004120000005,\n",
       " 0.04932074274,\n",
       " 0.06973229708,\n",
       " 0.15382658059999998,\n",
       " 0.90023017,\n",
       " 0.2544754514,\n",
       " 0.15558520732,\n",
       " 0.9013790100000001,\n",
       " 0.876603798,\n",
       " 0.6380354652,\n",
       " 0.084420262,\n",
       " 0.08747721134,\n",
       " 0.2452295646,\n",
       " 0.059935704199999995,\n",
       " 0.10970789403999999,\n",
       " 0.07910569174,\n",
       " 0.24706307379999998,\n",
       " 0.16041150320000003,\n",
       " 0.02923069542,\n",
       " 0.2998522788,\n",
       " 0.1182875986,\n",
       " 0.1145240654,\n",
       " 0.1670453584,\n",
       " 0.09839855574,\n",
       " 0.10936864612,\n",
       " 0.555111836,\n",
       " 0.124029078,\n",
       " 0.974305714,\n",
       " 0.3932169406,\n",
       " 0.39436101660000006,\n",
       " 0.077071732,\n",
       " 0.19050918079999998,\n",
       " 0.615652026,\n",
       " 0.15396408580000004,\n",
       " 0.8721068220000001,\n",
       " 0.925326436,\n",
       " 0.4035245672,\n",
       " 0.930540164,\n",
       " 0.1224250978,\n",
       " 0.0882676991,\n",
       " 0.03866377868399999,\n",
       " 0.680101826,\n",
       " 0.20339038465999998,\n",
       " 0.359270352,\n",
       " 0.083158649,\n",
       " 0.1082926452,\n",
       " 0.055382340399999994,\n",
       " 0.1479486778,\n",
       " 0.20137760999999998,\n",
       " 0.766302126,\n",
       " 0.48081657480000006,\n",
       " 0.06400839376,\n",
       " 0.03746223624,\n",
       " 0.640508304,\n",
       " 0.906381724,\n",
       " 0.0890986112,\n",
       " 0.37381073719999997,\n",
       " 0.16706581599999998,\n",
       " 0.09418597780000001,\n",
       " 0.21345206249999998,\n",
       " 0.122211819,\n",
       " 0.1118753754,\n",
       " 0.836653826,\n",
       " 0.807157034,\n",
       " 0.07319375659999999,\n",
       " 0.981117652,\n",
       " 0.17860361739999997,\n",
       " 0.062020251300000016,\n",
       " 0.1510254788,\n",
       " 0.0742470968,\n",
       " 0.723091652,\n",
       " 0.14742046839999998,\n",
       " 0.019568604219999997,\n",
       " 0.042110609846,\n",
       " 0.1047275008,\n",
       " 0.6023839559999999,\n",
       " 0.847753848,\n",
       " 0.0713364716,\n",
       " 0.26054945399999996,\n",
       " 0.522556288,\n",
       " 0.0649383224,\n",
       " 0.5621475260000001,\n",
       " 0.0987606772,\n",
       " 0.9598706399999999,\n",
       " 0.198951969352,\n",
       " 0.2204597572,\n",
       " 0.021421612359999998,\n",
       " 0.15719827059999997,\n",
       " 0.05998384180000001,\n",
       " 0.1112189624,\n",
       " 0.873371414,\n",
       " 0.20692614259999997,\n",
       " 0.0156490882,\n",
       " 0.25833926869999996,\n",
       " 0.5566540648,\n",
       " 0.6930133980000001,\n",
       " 0.28516089580000004,\n",
       " 0.09852717500000001,\n",
       " 0.727738754,\n",
       " 0.565258858,\n",
       " 0.3537140205,\n",
       " 0.835183782,\n",
       " 0.18783396640000002,\n",
       " 0.09806599880000001,\n",
       " 0.5079726786000001,\n",
       " 0.23392104279999998,\n",
       " 0.596273042,\n",
       " 0.5013255919999999,\n",
       " 0.470919622,\n",
       " 0.06153100140000001,\n",
       " 0.5725608583999999,\n",
       " 0.9560519380000001,\n",
       " 0.872541332,\n",
       " 0.360412258,\n",
       " 0.626645512,\n",
       " 0.08334133120000001,\n",
       " 0.25547863400000004,\n",
       " 0.08987643799999999,\n",
       " 0.2640297992,\n",
       " 0.096626662,\n",
       " 0.850545228,\n",
       " 0.073439494,\n",
       " 0.0427025008,\n",
       " 0.276899365008,\n",
       " 0.2612421508,\n",
       " 0.604806766,\n",
       " 0.5157434220000001,\n",
       " 0.919564584,\n",
       " 0.100424543646,\n",
       " 0.54534036,\n",
       " 0.755056484,\n",
       " 0.9121946040000001,\n",
       " 0.13770944159999998,\n",
       " 0.912994852,\n",
       " 0.946404892,\n",
       " 0.816635426,\n",
       " 0.689104958,\n",
       " 0.8840212080000001,\n",
       " 0.478518387,\n",
       " 0.27420262886,\n",
       " 0.2632063282,\n",
       " 0.5021738325999999,\n",
       " 0.0616504728,\n",
       " 0.045637984900000005,\n",
       " 0.13643674520000001,\n",
       " 0.21980232920000004,\n",
       " 0.86925274,\n",
       " 0.727004286,\n",
       " 0.2740346112,\n",
       " 0.9806569599999999,\n",
       " 0.12136018200000001,\n",
       " 0.495202888,\n",
       " 0.10057024960000001,\n",
       " 0.20912794674000001,\n",
       " 0.63188206,\n",
       " 0.678578306,\n",
       " 0.783730594,\n",
       " 0.664664388,\n",
       " 0.3008790206,\n",
       " 0.840777898,\n",
       " 0.04310512500000001,\n",
       " 0.1334266756,\n",
       " 0.9250773000000001,\n",
       " 0.0295378768,\n",
       " 0.488142124,\n",
       " 0.243472344,\n",
       " 0.39850491760000006,\n",
       " 0.07558711865,\n",
       " 0.58102619,\n",
       " 0.0984044536,\n",
       " 0.8488748640000001,\n",
       " 0.1820444304,\n",
       " 0.066928646,\n",
       " 0.02915790418,\n",
       " 0.03072355196,\n",
       " 0.94939143,\n",
       " 0.0670509712,\n",
       " 0.030308924499999994,\n",
       " 0.140261125,\n",
       " 0.920386618,\n",
       " 0.3510076132,\n",
       " 0.878842938,\n",
       " 0.50345108,\n",
       " 0.04364178596,\n",
       " 0.07289790533999999,\n",
       " 0.8664514280000001,\n",
       " 0.866991388,\n",
       " 0.08806690576000001,\n",
       " 0.13382135720000002,\n",
       " 0.8547510019999999,\n",
       " 0.740216506,\n",
       " 0.17301227400000002,\n",
       " 0.059083090680000006,\n",
       " 0.19172078919999996,\n",
       " 0.6474001348,\n",
       " 0.64396928,\n",
       " 0.378648664,\n",
       " 0.0525903588,\n",
       " 0.897735874,\n",
       " 0.8269624600000001,\n",
       " 0.5468784626,\n",
       " 0.310662828,\n",
       " 0.868283384,\n",
       " 0.03593116398,\n",
       " 0.9819553639999998,\n",
       " 0.829744768,\n",
       " 0.0858633154,\n",
       " 0.33447179239999997,\n",
       " 0.32684111400000004,\n",
       " 0.046483630634,\n",
       " 0.261251372,\n",
       " 0.03248412826,\n",
       " 0.04458832382,\n",
       " 0.20066380341999998,\n",
       " 0.292553552,\n",
       " 0.02294942988,\n",
       " 0.6833501639999999,\n",
       " 0.9607100899999999,\n",
       " 0.82748616,\n",
       " 0.7420363700000001,\n",
       " 0.06313053589999999,\n",
       " 0.0513357926,\n",
       " 0.4179189376000001,\n",
       " 0.9614296079999999,\n",
       " 0.20638214270000002,\n",
       " 0.09276763060000001,\n",
       " 0.033582241240000005,\n",
       " 0.41674716279999996,\n",
       " 0.84794068,\n",
       " 0.747656506,\n",
       " 0.850863116,\n",
       " 0.47583096400000013,\n",
       " 0.07940915149999998,\n",
       " 0.654074806,\n",
       " 0.65867493,\n",
       " 0.20372632999999998,\n",
       " 0.02107224138,\n",
       " 0.12315877,\n",
       " 0.07223053716,\n",
       " 0.943500566,\n",
       " 0.1190386328,\n",
       " 0.8223399560000001,\n",
       " 0.1355585932,\n",
       " 0.73283208,\n",
       " 0.6492273799999999,\n",
       " 0.33303161000000003,\n",
       " 0.1203704422,\n",
       " 0.1651858932,\n",
       " 0.07809893180000001,\n",
       " 0.14180676860000002,\n",
       " 0.579705988,\n",
       " 0.354527444,\n",
       " 0.10879431890999998,\n",
       " 0.984286642,\n",
       " 0.6935809479999999,\n",
       " 0.09344705319999999,\n",
       " 0.7970926819999999,\n",
       " 0.05974677529,\n",
       " 0.691807118,\n",
       " 0.05378184223999999,\n",
       " 0.0975157142,\n",
       " 0.0734007874,\n",
       " 0.03447726030800001,\n",
       " 0.7592335419999999,\n",
       " 0.28950281440000003,\n",
       " 0.09285003412,\n",
       " 0.38686527699999995,\n",
       " 0.70559387,\n",
       " 0.2669516296,\n",
       " 0.12887572860000002,\n",
       " 0.73201763,\n",
       " 0.09430641766,\n",
       " 0.544970174,\n",
       " 0.6283205592000001,\n",
       " 0.33542004400000003,\n",
       " 0.04619165996,\n",
       " 0.336012544,\n",
       " 0.155636991,\n",
       " 0.1694237965,\n",
       " 0.096276026634,\n",
       " 0.10058356579999998,\n",
       " 0.27738054160000003,\n",
       " 0.040697024580000005,\n",
       " 0.074780338,\n",
       " 0.1916730296,\n",
       " 0.0712825425,\n",
       " 0.585761002,\n",
       " 0.1063527116,\n",
       " 0.05275512786599999,\n",
       " 0.11607975899999998,\n",
       " 0.2715545656,\n",
       " 0.17945997226000002,\n",
       " 0.7369265079999999,\n",
       " 0.04286115134,\n",
       " 0.38279594,\n",
       " 0.8820873599999999,\n",
       " 0.05641021240000001,\n",
       " 0.00607365328,\n",
       " 0.66140726,\n",
       " 0.038370298819999996,\n",
       " 0.17715788999999998,\n",
       " 0.07295433616,\n",
       " 0.0796049366,\n",
       " 0.347025778,\n",
       " 0.04248241054,\n",
       " 0.908417712,\n",
       " 0.84571258,\n",
       " 0.799647634,\n",
       " 0.76120029,\n",
       " 0.43456231240000004,\n",
       " 0.3840509248,\n",
       " 0.1073544058,\n",
       " 0.45345650800000004,\n",
       " 0.0770129436,\n",
       " 0.014527508459999996,\n",
       " 0.6513964312,\n",
       " 0.694293578,\n",
       " 0.05084943280000002,\n",
       " 0.16027635264,\n",
       " 0.07196294818,\n",
       " 0.675719042,\n",
       " 0.10710635880000001,\n",
       " 0.09573828808,\n",
       " 0.3100348052,\n",
       " 0.10165398548,\n",
       " 0.86079711,\n",
       " 0.6815526195999999,\n",
       " 0.35649706458,\n",
       " 0.8344778500000001,\n",
       " 0.29686844,\n",
       " 0.359958304,\n",
       " 0.8811833099999999,\n",
       " 0.41648681199999993,\n",
       " 0.617232078,\n",
       " 0.9483356480000001,\n",
       " 0.10051642740399999,\n",
       " 0.747549246,\n",
       " 0.9038037219999999,\n",
       " 0.538177382,\n",
       " 0.2878680916,\n",
       " 0.3051716874,\n",
       " 0.0395717291,\n",
       " 0.05178476532,\n",
       " 0.0524324385,\n",
       " 0.03572720459999999,\n",
       " 0.687550932,\n",
       " 0.1408827034,\n",
       " 0.963273362,\n",
       " 0.13191101704,\n",
       " 0.7952545859999999,\n",
       " 0.64989086,\n",
       " 0.9787017,\n",
       " 0.7769738168,\n",
       " 0.0942106634,\n",
       " 0.0576902102,\n",
       " 0.07964476220000001,\n",
       " 0.7491807500000001,\n",
       " 0.04122408712,\n",
       " 0.52282322,\n",
       " 0.04530415066,\n",
       " 0.5113654000000001,\n",
       " 0.2500785376,\n",
       " 0.477627864,\n",
       " 0.46031312599999996,\n",
       " 0.07536364084,\n",
       " 0.23109760440000002,\n",
       " 0.7744506440000001,\n",
       " 0.34094111599999993,\n",
       " 0.14393918020000002,\n",
       " 0.12782488667999997,\n",
       " 0.366837072,\n",
       " 0.058304467400000004,\n",
       " 0.462558202,\n",
       " 0.312604843,\n",
       " 0.6278179560000001,\n",
       " 0.36180674678,\n",
       " 0.3809988616,\n",
       " 0.048392505524,\n",
       " 0.3183818612,\n",
       " 0.41973864,\n",
       " 0.23894685659999998,\n",
       " 0.08791730853999999,\n",
       " 0.92010956,\n",
       " 0.1782421914,\n",
       " 0.10239164508000001,\n",
       " 0.40042264140000006,\n",
       " 0.14263522720000002,\n",
       " 0.05972016050000001,\n",
       " 0.897024794,\n",
       " 0.041938875400000006,\n",
       " 0.253737854,\n",
       " 0.3717905572,\n",
       " 0.9923131040000002,\n",
       " 0.5362462668,\n",
       " 0.0697899964,\n",
       " 0.7374839659999999,\n",
       " 0.023316918939999997,\n",
       " 0.2519523994,\n",
       " 0.7443723660000001,\n",
       " 0.06294817327999999,\n",
       " 0.04470174702,\n",
       " 0.559834332,\n",
       " 0.04351557608,\n",
       " 0.659940962,\n",
       " 0.2460514158,\n",
       " 0.347774019,\n",
       " 0.45745303379999996,\n",
       " 0.03418909112,\n",
       " 0.486183476,\n",
       " 0.212612362,\n",
       " 0.9194447099999999,\n",
       " 0.568152972,\n",
       " 0.1954783714,\n",
       " 0.22138944,\n",
       " 0.21769586959999998,\n",
       " 0.0811625526,\n",
       " 0.1006520586,\n",
       " 0.1593446069,\n",
       " 0.177569464,\n",
       " 0.6706225119999999,\n",
       " 0.36877687200000003,\n",
       " 0.9050023279999999,\n",
       " 0.813478276,\n",
       " 0.9610276539999999,\n",
       " 0.5776997180000001,\n",
       " 0.910525084,\n",
       " 0.04864847302,\n",
       " 0.061031634759999995,\n",
       " 0.23936542198000002,\n",
       " 0.15116110928,\n",
       " 0.09295388169999999,\n",
       " 0.2184547508,\n",
       " 0.30313285419999997,\n",
       " 0.05805105260000001,\n",
       " 0.9819320979999999,\n",
       " 0.18598401,\n",
       " 0.828044226,\n",
       " 0.865685704,\n",
       " 0.30118859600000003,\n",
       " 0.573866,\n",
       " 0.02673015218,\n",
       " 0.988450282,\n",
       " 0.8588331559999999,\n",
       " 0.11813039083999999,\n",
       " 0.23576335180000002,\n",
       " 0.11540759149999999,\n",
       " 0.6510350619999999,\n",
       " 0.426001618,\n",
       " 0.7767771320000001,\n",
       " 0.2534219536,\n",
       " 0.03632315600000001,\n",
       " 0.5194941120000001,\n",
       " 0.03603321566,\n",
       " 0.04945985196,\n",
       " 0.2570229478,\n",
       " 0.020570303180000003,\n",
       " 0.2292253908,\n",
       " 0.164940975,\n",
       " 0.28172440400000004,\n",
       " 0.041196072832000004,\n",
       " 0.04696894848,\n",
       " 0.1025395354,\n",
       " 0.842408156,\n",
       " 0.03784553876,\n",
       " 0.42269550139999995,\n",
       " 0.9548419840000001,\n",
       " 0.1916820864,\n",
       " 0.537921616,\n",
       " 0.397623356,\n",
       " 0.05168549260000001,\n",
       " 0.0881347894,\n",
       " 0.9413585299999999,\n",
       " 0.43660210279999995,\n",
       " 0.654149478,\n",
       " 0.648796204,\n",
       " 0.20499641519999998,\n",
       " 0.16749413,\n",
       " 0.414006718,\n",
       " 0.38573856,\n",
       " 0.039102388599999996,\n",
       " 0.693529142,\n",
       " 0.9795796680000001,\n",
       " 0.1232307583,\n",
       " 0.3181386988,\n",
       " 0.731683,\n",
       " 0.46397047700000005,\n",
       " 0.025399187400000002,\n",
       " 0.1312236924,\n",
       " 0.257076386,\n",
       " 0.01842626728,\n",
       " 0.933815178,\n",
       " 0.1592470246,\n",
       " 0.910904658,\n",
       " 0.11019534366000001,\n",
       " 0.41015013079999996,\n",
       " 0.12323849800000002,\n",
       " 0.0753177168,\n",
       " 0.1727972192,\n",
       " 0.677377528,\n",
       " 0.03277006964,\n",
       " 0.1503787772,\n",
       " 0.134972481,\n",
       " 0.8238481799999999,\n",
       " 0.03778137656,\n",
       " 0.044729012,\n",
       " 0.854389336,\n",
       " 0.12401872660000002,\n",
       " 0.048722899586,\n",
       " 0.5546254088,\n",
       " 0.21565415400000001,\n",
       " 0.1990476638,\n",
       " 0.411611366,\n",
       " 0.8197360659999999,\n",
       " 0.9528642380000001,\n",
       " 0.5061467219999999,\n",
       " 0.909428962,\n",
       " 0.0797325074,\n",
       " 0.025881306660000002,\n",
       " 0.2088618742,\n",
       " 0.24371552480000003,\n",
       " 0.2569456154,\n",
       " 0.7854770999999999,\n",
       " 0.05049593139999999,\n",
       " 0.046929516000000004,\n",
       " 0.1186225478,\n",
       " 0.546757598,\n",
       " 0.8147180620000001,\n",
       " 0.11771428519999998,\n",
       " 0.1161569074,\n",
       " 0.06413698984,\n",
       " 0.969017818,\n",
       " 0.013614545220000001,\n",
       " 0.41882268599999994,\n",
       " 0.832686754,\n",
       " 0.7338435640000001,\n",
       " 0.858181442,\n",
       " 0.42493653,\n",
       " 0.5696571619999999,\n",
       " 0.375650554,\n",
       " 0.9202087999999999,\n",
       " 0.06685589389999999,\n",
       " 0.11689830500000001,\n",
       " 0.23998368080000004,\n",
       " 0.1904208158,\n",
       " 0.0955417186,\n",
       " 0.20472417959999997,\n",
       " 0.12537688239199998,\n",
       " 0.48637373000000006,\n",
       " 0.1329447105,\n",
       " 0.028286070899999998,\n",
       " 0.05654143022,\n",
       " 0.10526053654,\n",
       " 0.36377739500000006,\n",
       " 0.090373159,\n",
       " 0.28797077919999997,\n",
       " 0.9189546680000001,\n",
       " 0.17133766239999998,\n",
       " 0.46845013999999996,\n",
       " 0.9181772699999999,\n",
       " 0.7409931399999999,\n",
       " 0.0352392878,\n",
       " 0.29060120200000006,\n",
       " 0.933163696,\n",
       " 0.09292444289999999,\n",
       " 0.056696738999999996,\n",
       " 0.2700729158,\n",
       " 0.029024587726,\n",
       " 0.579801401,\n",
       " 0.08314542566000002,\n",
       " 0.4368429656,\n",
       " 0.8019502700000001,\n",
       " 0.13419859380000002,\n",
       " 0.15426336420000003,\n",
       " 0.1602985114,\n",
       " 0.9666353759999999,\n",
       " 0.568020744,\n",
       " 0.022624541619999997,\n",
       " 0.518708372,\n",
       " 0.5481312779999999,\n",
       " 0.07584315026,\n",
       " 0.939372734,\n",
       " 0.4012674652,\n",
       " 0.01193223966,\n",
       " 0.023398847346,\n",
       " 0.07952175160000001,\n",
       " 0.14152122159999997,\n",
       " 0.04722728788,\n",
       " 0.32757411818000004,\n",
       " 0.475249922,\n",
       " 0.2931039554,\n",
       " 0.230210549,\n",
       " 0.29756385,\n",
       " 0.0441893006,\n",
       " 0.8650955760000001,\n",
       " 0.21490301139999998,\n",
       " 0.03990124754,\n",
       " 0.33278540408,\n",
       " 0.02590022928,\n",
       " 0.2188173456,\n",
       " 0.02316720558,\n",
       " 0.2049673724,\n",
       " 0.405188812,\n",
       " 0.7094000739999999,\n",
       " 0.16860629,\n",
       " 0.9715368200000001,\n",
       " 0.374158917,\n",
       " 0.035136474359999996,\n",
       " 0.0574494523,\n",
       " 0.303096806,\n",
       " 0.28564980519999994,\n",
       " 0.184363176,\n",
       " 0.1431173947,\n",
       " 0.03453105498,\n",
       " 0.1998673812,\n",
       " 0.1678360236,\n",
       " 0.617643166,\n",
       " 0.9162814560000001,\n",
       " 0.827231896,\n",
       " 0.376131466,\n",
       " 0.4371231292,\n",
       " 0.19503286199999997,\n",
       " 0.17962997188000002,\n",
       " 0.03548925676,\n",
       " 0.09957731708000002,\n",
       " 0.053531395399999994,\n",
       " 0.17001887162,\n",
       " 0.3558819416,\n",
       " 0.79197367,\n",
       " 0.86252788,\n",
       " 0.3800499572,\n",
       " 0.3181438274,\n",
       " 0.9397413020000001,\n",
       " 0.0732339684,\n",
       " 0.08893213738,\n",
       " 0.07548533952,\n",
       " 0.8604535240000001,\n",
       " 0.600326714,\n",
       " 0.967669798,\n",
       " 0.2347798,\n",
       " 0.3473703578,\n",
       " 0.931640932,\n",
       " 0.031870833808,\n",
       " 0.07107507378000001,\n",
       " 0.627200906,\n",
       " 0.602760164,\n",
       " 0.7540467200000001,\n",
       " 0.04990081068,\n",
       " 0.0864740636,\n",
       " 0.1125249228,\n",
       " 0.558759506,\n",
       " 0.9575951400000001,\n",
       " 0.05285696142,\n",
       " 0.08847256482,\n",
       " 0.2456382826,\n",
       " 0.035253266379999995,\n",
       " 0.8356253600000001,\n",
       " 0.21291342019999998,\n",
       " 0.18300677179999997,\n",
       " 0.07604647151999999,\n",
       " 0.37407392559999997,\n",
       " 0.939519988,\n",
       " 0.0494119198,\n",
       " 0.027921826908000002,\n",
       " 0.25050811673999995,\n",
       " 0.46328359599999996,\n",
       " 0.2386128844,\n",
       " 0.11134288651999999,\n",
       " 0.4314492838,\n",
       " 0.0882957411,\n",
       " 0.28581181759999996,\n",
       " 0.81618721,\n",
       " 0.5913094539999999,\n",
       " 0.30305326299999996,\n",
       " 0.4793332598,\n",
       " 0.0552809639,\n",
       " 0.02276342242,\n",
       " 0.861165054,\n",
       " 0.13644887212000004,\n",
       " 0.04502783644,\n",
       " 0.795463656,\n",
       " 0.032910439,\n",
       " 0.4915169147999999,\n",
       " 0.8332128280000001,\n",
       " 0.29651141000000003,\n",
       " 0.755173432,\n",
       " 0.08845661129999997,\n",
       " 0.055249058880000014,\n",
       " 0.9631390659999999,\n",
       " 0.742593414,\n",
       " 0.29381008,\n",
       " 0.158113738,\n",
       " 0.10178350629999999,\n",
       " 0.846066454,\n",
       " 0.8620648,\n",
       " 0.64585355,\n",
       " 0.22173904551999998,\n",
       " 0.09528277124000001,\n",
       " 0.093205778,\n",
       " 0.1905297208,\n",
       " 0.963890202,\n",
       " 0.1124078972,\n",
       " 0.08988243807999999,\n",
       " 0.4018343625,\n",
       " 0.2223368864,\n",
       " 0.716642122,\n",
       " 0.25203596,\n",
       " 0.663700832,\n",
       " 0.72547962,\n",
       " 0.040728289220000005,\n",
       " 0.726581816,\n",
       " 0.720474586,\n",
       " 0.74014865,\n",
       " 0.07900183390000001,\n",
       " 0.9559817599999999,\n",
       " 0.070395719,\n",
       " 0.215681592,\n",
       " 0.50376133,\n",
       " 0.9609058099999999,\n",
       " 0.1584579444,\n",
       " 0.4484486146,\n",
       " 0.871409616,\n",
       " 0.40092894800000006,\n",
       " 0.12874999254,\n",
       " 0.06319722845999999,\n",
       " 0.1671964766,\n",
       " 0.36115781682,\n",
       " 0.87656051,\n",
       " 0.1037965646,\n",
       " 0.1494569356,\n",
       " 0.5561354099999999,\n",
       " 0.09888712252000001,\n",
       " 0.5638651769999999,\n",
       " 0.223097294,\n",
       " 0.3224758744,\n",
       " 0.04377699,\n",
       " 0.032306839,\n",
       " 0.20296315512000002,\n",
       " 0.864478156,\n",
       " 0.064980058,\n",
       " 0.854591832,\n",
       " 0.04102199848,\n",
       " 0.094514234,\n",
       " 0.08635421,\n",
       " 0.676977966,\n",
       " 0.89165351,\n",
       " 0.11031259519999999,\n",
       " 0.0429068848,\n",
       " 0.715070772,\n",
       " 0.2638324,\n",
       " 0.433430555,\n",
       " 0.6643327440000001,\n",
       " 0.6544218616,\n",
       " 0.0396528522,\n",
       " 0.054798363239999995,\n",
       " 0.24389749379999998,\n",
       " 0.21170899940000001,\n",
       " 0.748314892,\n",
       " 0.14548106586,\n",
       " 0.905413938,\n",
       " 0.1851273648,\n",
       " 0.03380269263999999,\n",
       " 0.9099045100000002,\n",
       " 0.10647698460000002,\n",
       " 0.558141564,\n",
       " 0.20546931392000004,\n",
       " 0.3994288664,\n",
       " 0.0842884372,\n",
       " 0.410265392,\n",
       " 0.35898487960000003,\n",
       " 0.7466630400000001,\n",
       " 0.796227548,\n",
       " 0.03496547478,\n",
       " 0.2975712194,\n",
       " 0.22251493079999998,\n",
       " 0.11629973419999999,\n",
       " 0.3468027928,\n",
       " 0.009818220366,\n",
       " 0.718616068,\n",
       " 0.17212265100000002,\n",
       " 0.590486156,\n",
       " 0.20589153040000002,\n",
       " 0.3115092039,\n",
       " 0.0642644466,\n",
       " 0.1637249214,\n",
       " 0.16081076219999998,\n",
       " 0.1907415696,\n",
       " 0.695261294,\n",
       " 0.045891101739999995,\n",
       " 0.28808275920000004,\n",
       " 0.8774037939999999,\n",
       " 0.8920886219999999,\n",
       " 0.1086522352,\n",
       " 0.44341732,\n",
       " 0.012228076899999999,\n",
       " 0.2937813884,\n",
       " 0.991925714,\n",
       " 0.32479329079999997,\n",
       " 0.44941797800000005,\n",
       " 0.1185117184,\n",
       " 0.43698056799999996,\n",
       " 0.04508842960000001,\n",
       " 0.514499996,\n",
       " 0.44268049,\n",
       " 0.0902613656,\n",
       " 0.06692062102,\n",
       " 0.19450074100000003,\n",
       " 0.3702053752,\n",
       " 0.13736766679999998,\n",
       " 0.549253876,\n",
       " 0.023760934939999995,\n",
       " 0.38282041999999994,\n",
       " 0.09081715404,\n",
       " 0.9169818599999999,\n",
       " 0.963526358,\n",
       " 0.0862201192,\n",
       " 0.980654636,\n",
       " 0.14065446660000003,\n",
       " 0.06540849278,\n",
       " 0.6840658900000001,\n",
       " 0.05572584500000001,\n",
       " 0.984007478,\n",
       " 0.07775268846000001,\n",
       " 0.08859855400000001,\n",
       " 0.56155211,\n",
       " 0.058834360919999995,\n",
       " 0.06164026050000001,\n",
       " 0.064665369,\n",
       " 0.908838254,\n",
       " 0.6255929125999999,\n",
       " 0.737048276,\n",
       " 0.789683228,\n",
       " 0.30500222096,\n",
       " 0.08408911720000001,\n",
       " 0.539208248,\n",
       " 0.2675229214,\n",
       " 0.196874,\n",
       " 0.8701440659999999,\n",
       " 0.3836121354,\n",
       " 0.981411464,\n",
       " 0.10291892690000001,\n",
       " 0.11421286399999997,\n",
       " 0.05826730570000001,\n",
       " 0.4447341636,\n",
       " 0.0749461018,\n",
       " 0.8092477520000001,\n",
       " 0.92765018,\n",
       " 0.073700943,\n",
       " 0.36151486800000004,\n",
       " 0.056541500460000005,\n",
       " 0.017612499572,\n",
       " 0.055358781999999995,\n",
       " 0.33593387999999996,\n",
       " 0.032250596209999996,\n",
       " 0.0896603115,\n",
       " 0.776172042,\n",
       " 0.38536767399999994,\n",
       " 0.893032252,\n",
       " 0.659352854,\n",
       " 0.93414441,\n",
       " 0.8825776599999999,\n",
       " 0.614882704,\n",
       " 0.3664271676,\n",
       " 0.03913398995999999,\n",
       " 0.6382417840000001,\n",
       " 0.547158414,\n",
       " 0.05229704208,\n",
       " 0.38237617,\n",
       " 0.9165937,\n",
       " 0.068385453,\n",
       " 0.212813723,\n",
       " 0.042950263800000006,\n",
       " 0.26432452279999996,\n",
       " 0.8104449600000001,\n",
       " 0.22285713359999998,\n",
       " 0.44090169259999995,\n",
       " 0.281123323,\n",
       " 0.7460823079999999,\n",
       " 0.12993681279999997,\n",
       " 0.31167800300000004,\n",
       " 0.36963993679999996,\n",
       " 0.24522925040000004,\n",
       " 0.9060923599999999,\n",
       " 0.10640661660000002,\n",
       " 0.19719794200000001,\n",
       " 0.27091890400000007,\n",
       " 0.1086870248,\n",
       " 0.030989119,\n",
       " 0.1366699032,\n",
       " 0.5161943724,\n",
       " 0.715255516,\n",
       " 0.49243511040000004,\n",
       " 0.63572099,\n",
       " 0.449357646,\n",
       " 0.1345129722,\n",
       " 0.523276794,\n",
       " 0.23225882739999998,\n",
       " 0.58254316,\n",
       " 0.036592213979999996,\n",
       " 0.03576627732,\n",
       " 0.07604911056,\n",
       " 0.46416574199999994,\n",
       " 0.464468298,\n",
       " 0.6448533134,\n",
       " 0.04152199552000001,\n",
       " 0.583211296,\n",
       " 0.1793696598,\n",
       " 0.4547936760000001,\n",
       " 0.23806954660000001,\n",
       " ...]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f6d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that handles sample splitting, model fitting and report printing \n",
    "def mfunc(X, y, typ):\n",
    "    \n",
    "    # Create training and testing samples\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    model = typ\n",
    "    clf = model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels = model.predict(X_test)\n",
    "\n",
    "    # Print model attributes \n",
    "    print('Classes: ', clf.classes_) # class labels known to the classifier\n",
    "    if str(typ)=='GaussianNB()':\n",
    "        print('Class Priors: ',clf.class_prior_) # prior probability of each class.\n",
    "    else: \n",
    "        print('Class Log Priors: ',clf.class_log_prior_) # log prior probability of each class.\n",
    "        \n",
    "    # Use score method to get accuracy of the model\n",
    "    print('--------------------------------------------------------')\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Accuracy Score: ', score)\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_test, pred_labels))\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X_train, X_test, y_train, y_test, clf, pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baafce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for modeling\n",
    "X=df[['opening_eco', 'white_id']]\n",
    "y=df['white_win'].values\n",
    "\n",
    "# Encode categorical variables\n",
    "enc = OrdinalEncoder()\n",
    "X = enc.fit_transform(X)\n",
    "\n",
    "# Fit the model and print the result\n",
    "X_train, X_test, y_train, y_test, clf, pred_labels = mfunc(X, y, CategoricalNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15022ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdd5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
