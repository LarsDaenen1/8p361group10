{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96138156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All imports\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#import models\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd46d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd95fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "    # dataset parameters\n",
    "    train_path = os.path.join(base_dir, 'train+val', 'train')\n",
    "    valid_path = os.path.join(base_dir, 'train+val', 'valid')\n",
    "\n",
    "    # instantiate data generators\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bdad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pretrained(pretrained_network):\n",
    "    \n",
    "    output = pretrained_network(input)\n",
    "    output = GlobalAveragePooling2D()(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "    model = Model(input, output)\n",
    "\n",
    "    # note the lower lr compared to the cnn example\n",
    "    model.compile(SGD(learning_rate=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # print a summary of the model on screen\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02570492",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "input = Input(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a3ea0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " xception (Functional)       (None, 3, 3, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_Xception = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "names = [ \"Xception\"]\n",
    "models = [prepare_pretrained(pretrained_Xception)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f65c8d2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\20192653\\\\Documents\\\\8P361 - Project imaging\\\\8p361-project-imaging-master\\\\8p361-project-imaging-master\\\\data\\\\train+val\\\\train+val\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8264/1231822584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# get the data generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pcam_generators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\20192653\\Documents\\8P361 - Project imaging\\8p361-project-imaging-master\\8p361-project-imaging-master\\data\\train+val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8264/2655358520.py\u001b[0m in \u001b[0;36mget_pcam_generators\u001b[1;34m(base_dir, train_batch_size, val_batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdatagen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     train_gen = datagen.flow_from_directory(train_path,\n\u001b[0m\u001b[0;32m     11\u001b[0m                                              \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    974\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \"\"\"\n\u001b[1;32m--> 976\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    977\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\8p361\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\20192653\\\\Documents\\\\8P361 - Project imaging\\\\8p361-project-imaging-master\\\\8p361-project-imaging-master\\\\data\\\\train+val\\\\train+val\\\\train'"
     ]
    }
   ],
   "source": [
    "# get the data generators\n",
    "train_gen, val_gen = get_pcam_generators(r'C:\\Users\\20192653\\Documents\\8P361 - Project imaging\\8p361-project-imaging-master\\8p361-project-imaging-master\\data\\train+val')\n",
    "\n",
    "\n",
    "for i,model in enumerate(models):\n",
    "    # save the model and weights\n",
    "    model_name = names[i]\n",
    "    model_filepath = model_name + '.json'\n",
    "    weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "    model_json = model.to_json() # serialize model to JSON\n",
    "    with open(model_filepath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "\n",
    "    # define the model checkpoint and Tensorboard callbacks\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=10, verbose=1), tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1)]\n",
    "    #callbacks = [tf.keras.callbacks.EarlyStopping(patience=10, verbose=1), tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1)]\n",
    "    checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "    callbacks_list = [checkpoint, tensorboard] + callbacks\n",
    "\n",
    "\n",
    "    # train the model, note that we define \"mini-epochs\"\n",
    "    train_steps = train_gen.n//train_gen.batch_size//20\n",
    "    val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "\n",
    "    history = model.fit(train_gen, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=20,\n",
    "                        callbacks=callbacks_list)\n",
    "    model = tf.keras.models.load_model(weights_filepath)\n",
    "    y_pred = model.predict(val_gen, verbose=1).ravel()\n",
    "    y_true = val_gen.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0db76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(weights_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
