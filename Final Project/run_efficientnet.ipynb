{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ecc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable overly verbose tensorflow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d288a",
   "metadata": {},
   "source": [
    "## Import model of interest (change cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a294c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB5, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8f0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train+val', 'train')\n",
    "     valid_path = os.path.join(base_dir, 'train+val', 'valid')\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary',shuffle=False)\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary',shuffle=False)\n",
    "\n",
    "     return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eaae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "input = Input(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dd400",
   "metadata": {},
   "source": [
    "## Import pretrained model (change cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba38ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = EfficientNetB5(input_shape=input_shape, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9b582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetb5 (Functional)  (None, 3, 3, 2048)       28513527  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,515,576\n",
      "Trainable params: 28,342,833\n",
      "Non-trainable params: 172,743\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20192653\\Anaconda3\\envs\\8p361\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "output = pretrained(input)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "# note the lower lr compared to the cnn example\n",
    "model.compile(SGD(lr=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print a summary of the model on screen\n",
    "model.summary()\n",
    "\n",
    "# get the data generators\n",
    "train_gen, val_gen = get_pcam_generators(r\"C:\\Users\\20192653\\Documents\\8P361 - Project imaging\\8p361-project-imaging-master\\8p361-project-imaging-master\\data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12974fb",
   "metadata": {},
   "source": [
    "## Save model and weights (change cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5851948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'EfficientNetB5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6be772d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8754bb",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9678bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20192653\\AppData\\Local\\Temp/ipykernel_2832/2515729185.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "# train the model, note that we define \"mini-epochs\"\n",
    "train_steps = train_gen.n//train_gen.batch_size//20\n",
    "val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "# since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "# not used during training\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=20,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b10a28",
   "metadata": {},
   "source": [
    "## ROC analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabed258",
   "metadata": {},
   "source": [
    "## import matplotlib.pyplot as plt\n",
    "\n",
    "model = tf.keras.models.load_model(weights_filepath)\n",
    "y_pred = model.predict(val_gen).ravel()\n",
    "y_true = val_gen.labels\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "from sklearn.metrics import auc\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Keras (area = {:.3f})'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
